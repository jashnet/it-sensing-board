import streamlit as st
import feedparser
import google.generativeai as genai
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime, timedelta
import time
from deep_translator import GoogleTranslator
import requests

# --- 1. ì„¤ì • ë° ë¡œë“œ (í”„ë¡¬í”„íŠ¸ ì´ì›í™”) ---
SETTINGS_FILE = "nod_v4_settings.json"

def load_settings():
    if os.path.exists(SETTINGS_FILE):
        try:
            with open(SETTINGS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except: return default_settings()
    return default_settings()

def default_settings():
    return {
        "api_key": "",
        "slack_webhook": "",
        "sensing_period": 7,
        # í”„ë¡¬í”„íŠ¸ 1: ë‰´ìŠ¤ ë…¸ì¶œ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” í•„í„° ê¸°ì¤€
        "filter_prompt": "ì°¨ì„¸ëŒ€ ê²½í—˜ ê¸°íš(NOD)ì— ì˜ê°ì„ ì£¼ëŠ” AI í•˜ë“œì›¨ì–´, í˜ì‹ ì  UX, ì›¨ì–´ëŸ¬ë¸” ë‰´ìŠ¤ë§Œ í¬í•¨í•  ê²ƒ. ë‹¨ìˆœ ì£¼ì‹ ë‰´ìŠ¤ë‚˜ ì¼ë°˜ SW ì—…ë°ì´íŠ¸ëŠ” ì œì™¸.",
        # í”„ë¡¬í”„íŠ¸ 2: Deep-dive ë¶„ì„ì˜ í˜•ì‹ì„ ê²°ì •í•˜ëŠ” ê¸°ì¤€
        "ai_analysis_prompt": "ì´ ì œí’ˆì˜ UX ë³€ê³¡ì ì„ ë¶„ì„í•˜ê³ , ìš°ë¦¬ íŒ€ì˜ ì „ëµì— ì´ì‹í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ì•„ì´ë””ì–´ 2ê°œë¥¼ ì œì•ˆí•˜ë¼.",
        "channels": {
            "ê¸€ë¡œë²Œ": [{"name": "The Verge", "url": "https://www.theverge.com/rss/index.xml", "active": True},
                     {"name": "Wired", "url": "https://www.wired.com/feed/rss", "active": True}],
            "ì¤‘êµ­": [{"name": "36Kr", "url": "https://36kr.com/feed", "active": True}],
            "ì¼ë³¸": [{"name": "The Bridge JP", "url": "https://thebridge.jp/feed", "active": True}]
        }
    }

def save_settings(settings):
    with open(SETTINGS_FILE, "w", encoding="utf-8") as f:
        json.dump(settings, f, ensure_ascii=False, indent=4)

if "settings" not in st.session_state:
    st.session_state.settings = load_settings()

# --- 2. ì¸ë„¤ì¼ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def get_robust_thumbnail(entry):
    if 'media_content' in entry: return entry.media_content[0]['url']
    link = entry.get('link')
    if link:
        try:
            res = requests.get(link, timeout=1.0)
            if res.status_code == 200:
                soup = BeautifulSoup(res.text, 'html.parser')
                og_img = soup.find("meta", property="og:image")
                if og_img: return og_img["content"]
        except: pass
    return f"https://via.placeholder.com/600x400/1a73e8/ffffff?text=NOD+Sensing"

def get_ai_model():
    api_key = st.session_state.settings.get("api_key")
    if not api_key: return None
    try:
        genai.configure(api_key=api_key)
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        target = next((m for m in available_models if "1.5-flash" in m), available_models[0])
        return genai.GenerativeModel(target)
    except: return None

# --- 3. UI ë° ìŠ¤íƒ€ì¼ë§ ---
st.set_page_config(page_title="NOD Intelligence Hub", layout="wide")
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;700&display=swap');
    html, body, [class*="css"] { font-family: 'Noto Sans KR', sans-serif; background-color: #f8f9fa; }
    .card { background: white; padding: 22px; border-radius: 18px; box-shadow: 0 4px 15px rgba(0,0,0,0.05); border: 1px solid #eef1f4; margin-bottom: 20px; }
    .thumbnail { width: 100%; height: 180px; object-fit: cover; border-radius: 12px; margin-bottom: 12px; }
    .card-title { font-size: 1rem; font-weight: 700; height: 48px; overflow: hidden; color: #1a1c1e; }
    .badge { background: #f0f4ff; color: #1a73e8; padding: 4px 10px; border-radius: 6px; font-size: 0.75rem; font-weight: 700; margin-bottom: 10px; display: inline-block; }
</style>
""", unsafe_allow_html=True)

# --- 4. ì‚¬ì´ë“œë°” (ê°œí¸ëœ í”„ë¡¬í”„íŠ¸ ì„¤ì •) ---
with st.sidebar:
    st.title("ğŸ›¡ï¸ NOD ì „ëµ ì„¼í„°")
    
    if st.session_state.settings.get("api_key"):
        st.success("âœ… AI ê°€ë™ ì¤‘")
        if st.button("Key ë³€ê²½"): st.session_state.settings["api_key"] = ""; st.rerun()
    else:
        new_key = st.text_input("Gemini API Key ì…ë ¥", type="password")
        if st.button("ì—°ê²°"): 
            st.session_state.settings["api_key"] = new_key
            save_settings(st.session_state.settings); st.rerun()

    st.divider()
    st.subheader("ğŸŒ ì±„ë„ ê´€ë¦¬")
    for cat, feeds in st.session_state.settings["channels"].items():
        with st.expander(cat):
            for f in feeds:
                f["active"] = st.checkbox(f["name"], value=f["active"], key=f"ch_{f['name']}")

    st.divider()
    with st.expander("âš™ï¸ ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì„¤ì •"):
        st.markdown("### 1ï¸âƒ£ ë‰´ìŠ¤ í•„í„° í”„ë¡¬í”„íŠ¸")
        st.caption("ì–´ë–¤ ë‰´ìŠ¤ë¥¼ ëŒ€ì‹œë³´ë“œì— ë…¸ì¶œí• ì§€ ê²°ì •í•©ë‹ˆë‹¤.")
        st.session_state.settings["filter_prompt"] = st.text_area("í•„í„° ê¸°ì¤€", value=st.session_state.settings["filter_prompt"], height=100)
        
        st.markdown("### 2ï¸âƒ£ AI ë¶„ì„ í”„ë¡¬í”„íŠ¸")
        st.caption("Deep-dive ë¦¬í¬íŠ¸ì˜ ë¶„ì„ ê´€ì ì„ ê²°ì •í•©ë‹ˆë‹¤.")
        st.session_state.settings["ai_analysis_prompt"] = st.text_area("ë¶„ì„ ê°€ì´ë“œ", value=st.session_state.settings["ai_analysis_prompt"], height=100)
        
        st.markdown("### ğŸ“… ìˆ˜ì§‘ í™˜ê²½")
        st.session_state.settings["slack_webhook"] = st.text_input("Slack Webhook URL", value=st.session_state.settings.get("slack_webhook", ""))
        st.session_state.settings["sensing_period"] = st.slider("ìˆ˜ì§‘ ê¸°ê°„(ì¼)", 1, 30, st.session_state.settings["sensing_period"])
        
        if st.button("ëª¨ë“  ì„¤ì • ì¼ê´„ ì €ì¥"):
            save_settings(st.session_state.settings)
            st.toast("ì „ëµ ê¸°ì¤€ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ’¾")

# --- 5. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ë° AI í•„í„°ë§ ---
@st.cache_data(ttl=3600)
def fetch_and_filter():
    results = []
    limit = datetime.now() - timedelta(days=st.session_state.settings["sensing_period"])
    translator = GoogleTranslator(source='auto', target='ko')
    
    # 1ë‹¨ê³„: ì „ì²´ ë‰´ìŠ¤ ìˆ˜ì§‘
    temp_list = []
    for cat, feeds in st.session_state.settings["channels"].items():
        for f in feeds:
            if not f.get("active"): continue
            d = feedparser.parse(f["url"])
            for entry in d.entries[:10]:
                try:
                    p_date = datetime.fromtimestamp(time.mktime(entry.published_parsed))
                    if p_date < limit: continue
                    temp_list.append({
                        "title_en": entry.title,
                        "summary_en": BeautifulSoup(entry.get("summary", ""), "html.parser").get_text()[:300],
                        "link": entry.link, "source": f["name"], "date": p_date.strftime("%m/%d"),
                        "raw_entry": entry
                    })
                except: continue

    # 2ë‹¨ê³„: AI ëª¨ë¸ ë¡œë“œ (í•„í„°ë§ìš©)
    model = get_ai_model()
    st.write(f"ğŸ”„ AIê°€ {len(temp_list)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ì „ëµì  ê°€ì¹˜ë¡œ ì„ ë³„ ì¤‘...")
    
    # 3ë‹¨ê³„: í•„í„°ë§ ë° ë²ˆì—­
    for item in temp_list:
        if model:
            # í•„í„° í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¸ì¶œ ì—¬ë¶€ ê²°ì •
            filter_check = model.generate_content(f"ê¸°ì¤€: {st.session_state.settings['filter_prompt']}\n\në‰´ìŠ¤ ì œëª©: {item['title_en']}\nìœ„ ê¸°ì¤€ì— ë¶€í•©í•˜ë©´ 'Yes', ì•„ë‹ˆë©´ 'No'ë¼ê³ ë§Œ ë‹µí•´.")
            if "yes" not in filter_check.text.lower(): continue

        # í†µê³¼ëœ ë‰´ìŠ¤ë§Œ ë²ˆì—­ ë° ì´ë¯¸ì§€ ì¶”ì¶œ
        results.append({
            "title": translator.translate(item['title_en']),
            "summary": translator.translate(item['summary_en'][:150]),
            "img": get_robust_thumbnail(item['raw_entry']),
            "source": item['source'], "date": item['date'], "link": item['link']
        })
    return results

# --- 6. ë©”ì¸ í™”ë©´ ---
st.title("ğŸš€ NOD Intelligence Hub")
news_data = fetch_and_filter()

model = get_ai_model()

if news_data:
    rows = [news_data[i:i + 3] for i in range(0, len(news_data), 3)]
    for row in rows:
        cols = st.columns(3)
        for j, item in enumerate(row):
            with cols[j]:
                st.markdown(f"""
                <div class="card">
                    <div class="badge">{item['source']} | {item['date']}</div>
                    <img src="{item['img']}" class="thumbnail">
                    <div class="card-title">{item['title']}</div>
                    <div style="font-size:0.85rem; color:#515458; height:60px; overflow:hidden;">{item['summary']}...</div>
                </div>
                """, unsafe_allow_html=True)
                
                if st.button("ğŸ” ì „ëµ Deep-dive", key=f"btn_{item['link'][-15:]}"):
                    if model:
                        with st.spinner("ë¶„ì„ ì¤‘..."):
                            # ë¶„ì„ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦¬í¬íŠ¸ ìƒì„±
                            prompt = f"{st.session_state.settings['ai_analysis_prompt']}\n\nëŒ€ìƒ: {item['title']} - {item['summary']}"
                            res = model.generate_content(prompt)
                            st.info(res.text)
                            
                            # ìŠ¬ë™ ì „ì†¡ (ê³ ê¸‰ ì„¤ì •ì— URL ìˆì„ ë•Œë§Œ)
                            if st.session_state.settings.get("slack_webhook"):
                                if st.button("ğŸ“¢ ìŠ¬ë™ ê³µìœ ", key=f"sl_{item['link'][-15:]}"):
                                    requests.post(st.session_state.settings["slack_webhook"], json={"text": f"*NOD ì¸ì‚¬ì´íŠ¸:* {item['title']}\n{res.text}"})
                                    st.toast("ìŠ¬ë™ ì „ì†¡ ì™„ë£Œ!")
                    else: st.warning("í‚¤ ë“±ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤.")
else:
    st.info("í˜„ì¬ í•„í„° ê¸°ì¤€ì— ë§ëŠ” í˜ì‹ ì ì¸ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. 'ê³ ê¸‰ ì„¤ì •'ì—ì„œ í•„í„° í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ì •í•´ ë³´ì„¸ìš”.")
