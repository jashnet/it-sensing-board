import streamlit as st
import feedparser
import google.generativeai as genai
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime, timedelta
import time
from deep_translator import GoogleTranslator
import requests
import hashlib

# --- 1. ì„¤ì • ë° ê¸°ë³¸ê°’ (ê°œì„ ëœ í•„í„° ë° ê°œìˆ˜ ì„¤ì • í¬í•¨) ---
SETTINGS_FILE = "nod_samsung_v7_settings.json"
DEFAULT_API_KEY = "AIzaSyCW7kwkCqCSN-usKFG9gwcPzYlHwtQW_DQ"

def default_settings():
    return {
        "api_key": DEFAULT_API_KEY,
        "slack_webhook": "",
        "sensing_period": 7,
        "filter_prompt": "ì‚¼ì„±ì „ìì˜ ì°¨ì„¸ëŒ€ ê²½í—˜ê¸°íšì— ì˜ê°ì„ ì£¼ëŠ” í˜ì‹  ê¸°ìˆ  ë° UX ì‚¬ë¡€.",
        "additional_filter": "",
        "filter_strength": 3,
        "max_articles": 20,
        "category_active": {"Global Innovation (23)": True, "China AI/HW (11)": True, "Japan Innovation (11)": True},
        "channels": {
            "Global Innovation (23)": [
                {"name": "The Verge", "url": "https://www.theverge.com/rss/index.xml", "active": True},
                {"name": "Wired", "url": "https://www.wired.com/feed/rss", "active": True}
            ],
            "China AI/HW (11)": [{"name": "36Kr (CN)", "url": "https://36kr.com/feed", "active": True}],
            "Japan Innovation (11)": [{"name": "The Bridge JP", "url": "https://thebridge.jp/feed", "active": True}]
        }
    }

def load_settings():
    if os.path.exists(SETTINGS_FILE):
        try:
            with open(SETTINGS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except: return default_settings()
    return default_settings()

def save_settings(settings):
    with open(SETTINGS_FILE, "w", encoding="utf-8") as f:
        json.dump(settings, f, ensure_ascii=False, indent=4)

if "settings" not in st.session_state:
    st.session_state.settings = load_settings()

# --- 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ì´ë¯¸ì§€, ë²ˆì—­, AI ëª¨ë¸) ---
def get_bulletproof_thumbnail(link):
    if not link: return "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=600&q=80"
    # ì¸ë„¤ì¼ ì—†ìœ¼ë©´ ì‹¤ì‹œê°„ ìŠ¤í¬ë¦°ìƒ· ì„œë¹„ìŠ¤ ì´ìš©
    return f"https://s.wordpress.com/mshots/v1/{link}?w=600"

def natural_translate(text):
    if not text: return ""
    try: return GoogleTranslator(source='auto', target='ko').translate(text)
    except: return text

def get_ai_model():
    try:
        genai.configure(api_key=st.session_state.settings["api_key"])
        return genai.GenerativeModel('gemini-1.5-flash-latest')
    except: return None

# --- 3. UI ìŠ¤íƒ€ì¼ ---
st.set_page_config(page_title="Samsung NOD Hub v7", layout="wide")
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;700&display=swap');
    body { font-family: 'Noto Sans KR', sans-serif; background-color: #f4f7fa; }
    .stButton>button { border-radius: 8px; width: 100%; }
    .card { background: white; padding: 22px; border-radius: 20px; box-shadow: 0 4px 15px rgba(0,0,0,0.05); height: 100%; border-top: 5px solid #034EA2; }
    .thumbnail { width: 100%; height: 180px; object-fit: cover; border-radius: 12px; margin-bottom: 12px; border: 1px solid #eee; }
</style>
""", unsafe_allow_html=True)

# --- 4. ì‚¬ì´ë“œë°” (í•„í„°ë§ ë° ì±„ë„ ê´€ë¦¬ ê³ ë„í™”) ---
with st.sidebar:
    st.title("ğŸ›¡ï¸ NOD ì „ëµ ê´€ì œ")
    
    # API í‚¤ ê´€ë¦¬
    if "edit_key" not in st.session_state: st.session_state.edit_key = False
    if st.session_state.settings["api_key"] and not st.session_state.edit_key:
        st.success("AI ì—°ê²°ë¨")
        if st.button("í‚¤ ìˆ˜ì •"): st.session_state.edit_key = True; st.rerun()
    else:
        new_key = st.text_input("Gemini API Key", value=st.session_state.settings["api_key"], type="password")
        if st.button("ì €ì¥"): st.session_state.settings["api_key"] = new_key; st.session_state.edit_key = False; save_settings(st.session_state.settings); st.rerun()

    st.divider()
    
    # ì±„ë„ ê·¸ë£¹ On/Off ë° ì¶”ê°€
    st.subheader("ğŸŒ ì±„ë„ ê·¸ë£¹ ê´€ë¦¬")
    for cat in list(st.session_state.settings["channels"].keys()):
        is_on = st.toggle(f"{cat} í™œì„±í™”", value=st.session_state.settings["category_active"].get(cat, True), key=f"tg_{cat}")
        st.session_state.settings["category_active"][cat] = is_on
        
        if is_on:
            with st.expander(f"{cat} ì±„ë„ ëª©ë¡"):
                for f in st.session_state.settings["channels"][cat]:
                    f["active"] = st.checkbox(f["name"], value=f["active"], key=f"ch_{f['name']}")
                
                st.markdown("---")
                st.caption("â• ì±„ë„ ì¶”ê°€")
                with st.form(key=f"add_form_{cat}"):
                    n_name = st.text_input("ì´ë¦„")
                    n_url = st.text_input("RSS URL")
                    if st.form_submit_button("ì¶”ê°€"):
                        st.session_state.settings["channels"][cat].append({"name": n_name, "url": n_url, "active": True})
                        save_settings(st.session_state.settings); st.rerun()

    st.divider()
    
    # ê³ ê¸‰ í•„í„° ì„¤ì •
    st.subheader("âš™ï¸ í•„í„° ì‹œìŠ¤í…œ")
    st.session_state.settings["filter_prompt"] = st.text_area("ê¸°ë³¸ ë‰´ìŠ¤ í•„í„°", value=st.session_state.settings["filter_prompt"])
    st.session_state.settings["additional_filter"] = st.text_area("Additional Filter (ê°€ì¤‘ì¹˜ í‚¤ì›Œë“œ)", value=st.session_state.settings.get("additional_filter", ""), help="ì—¬ê¸°ì— ì íŒ ë‚´ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ë²ˆ ë” í•„í„°ë§í•©ë‹ˆë‹¤.")
    
    st.session_state.settings["filter_strength"] = st.slider("Filter ê°•ë„ (1:ë‚®ìŒ ~ 5:ì—„ê²©)", 1, 5, st.session_state.settings["filter_strength"])
    st.session_state.settings["max_articles"] = st.selectbox("í‘œì‹œ ê¸°ì‚¬ ê°œìˆ˜", [10, 20, 30, 50], index=[10, 20, 30, 50].index(st.session_state.settings.get("max_articles", 20)))
    
    if st.button("ğŸš€ Apply & Refresh", use_container_width=True):
        save_settings(st.session_state.settings)
        st.cache_data.clear() # ìºì‹œ ì‚­ì œ í›„ ë¦¬í”„ë ˆì‹œ
        st.rerun()

# --- 5. ë°ì´í„° ì—”ì§„ (Sorting/Filtering ë¡œì§ í¬í•¨) ---
@st.cache_data(ttl=3600)
def fetch_sensing_data(settings):
    all_news = []
    limit = datetime.now() - timedelta(days=settings["sensing_period"])
    model = get_ai_model()
    
    # ê°•ë„ì— ë”°ë¥¸ AI ì§€ì‹œë¬¸ ì¡°ì ˆ
    strength_map = {1: "ê´€ë ¨ì´ ì¡°ê¸ˆì´ë¼ë„ ìˆë‹¤ë©´ í¬í•¨", 2: "ì ë‹¹íˆ í¬í•¨", 3: "ê´€ë ¨ì„± ìœ„ì£¼ë¡œ í•„í„°", 4: "ì—„ê²©í•˜ê²Œ í•„í„°", 5: "ë§¤ìš° ë°€ì ‘í•œ ë‰´ìŠ¤ë§Œ ì—„ì„ "}
    
    for cat, feeds in settings["channels"].items():
        if not settings["category_active"].get(cat): continue
        for f in feeds:
            if not f.get("active"): continue
            d = feedparser.parse(f["url"])
            for entry in d.entries[:15]: # ìˆ˜ì§‘ì€ ë„‰ë„‰í•˜ê²Œ
                try:
                    p_date = datetime.fromtimestamp(time.mktime(entry.published_parsed))
                    if p_date < limit: continue
                    
                    relevance_score = 5 # ê¸°ë³¸ ì ìˆ˜
                    if model:
                        # í•„í„°ë§ + ê´€ë ¨ë„ ì ìˆ˜ ì¸¡ì •
                        filter_query = f"""
                        [ê¸°ì¤€] {settings['filter_prompt']} 
                        [ì¶”ê°€ ê°€ì¤‘ì¹˜] {settings['additional_filter']}
                        [ê°•ë„] {strength_map[settings['filter_strength']]}
                        [ë‰´ìŠ¤ ì œëª©] {entry.title}
                        ê²°ê³¼ë¥¼ 'ìœ íš¨ì—¬ë¶€(True/False),ê´€ë ¨ì ìˆ˜(1-10)' í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•´. ì˜ˆ: True,8
                        """
                        check = model.generate_content(filter_query).text.strip()
                        if "true" not in check.lower(): continue
                        try: relevance_score = int(check.split(",")[1])
                        except: relevance_score = 5

                    all_news.append({
                        "id": hashlib.md5(entry.link.encode()).hexdigest()[:12],
                        "title_en": entry.title,
                        "title_ko": natural_translate(entry.title),
                        "summary": natural_translate(BeautifulSoup(entry.get("summary", ""), "html.parser").get_text()[:250]),
                        "img": get_bulletproof_thumbnail(entry.link),
                        "source": f["name"], "category": cat,
                        "date": p_date, "score": relevance_score, "link": entry.link
                    })
                except: continue
    return all_news

# --- 6. ëŒ€ì‹œë³´ë“œ ë©”ì¸ ì œì–´ ---
st.title("ğŸš€ Samsung NOD Strategy Hub v7")
data = fetch_sensing_data(st.session_state.settings)

if data:
    # ìƒë‹¨ ì»¨íŠ¸ë¡¤ ë°” (ë³¸ë¬¸ ë‚´ ì •ë ¬/í•„í„°)
    c1, c2, c3 = st.columns([2, 2, 2])
    with c1:
        sort_option = st.selectbox("ğŸ“… ì •ë ¬ ê¸°ì¤€", ["ìµœì‹ ìˆœ", "ê³¼ê±°ìˆœ", "AI ê´€ë ¨ë„ ë†’ì€ ìˆœ"])
    with c2:
        filter_cat = st.multiselect("ğŸ“‚ ì¹´í…Œê³ ë¦¬ í•„í„°", list(st.session_state.settings["channels"].keys()), default=list(st.session_state.settings["channels"].keys()))
    with c3:
        search_query = st.text_input("ğŸ” ê²°ê³¼ ë‚´ ê²€ìƒ‰", "")

    # ì •ë ¬ ë° í•„í„° ì ìš©
    filtered_data = [d for d in data if d["category"] in filter_cat]
    if search_query:
        filtered_data = [d for d in filtered_data if search_query.lower() in d["title_ko"].lower() or search_query.lower() in d["title_en"].lower()]
    
    if sort_option == "ìµœì‹ ìˆœ": filtered_data.sort(key=lambda x: x["date"], reverse=True)
    elif sort_option == "ê³¼ê±°ìˆœ": filtered_data.sort(key=lambda x: x["date"])
    else: filtered_data.sort(key=lambda x: x["score"], reverse=True)

    # ê°œìˆ˜ ì œí•œ ì ìš©
    display_data = filtered_data[:st.session_state.settings["max_articles"]]

    # ê²°ê³¼ ì¶œë ¥
    st.subheader(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(display_data)}ê°œ ê¸°ì‚¬")
    
    # Top 6 (ìµœìƒë‹¨)
    top_6 = display_data[:6]
    grid = [top_6[i:i+3] for i in range(0, len(top_6), 3)]
    for row in grid:
        cols = st.columns(3)
        for j, item in enumerate(row):
            with cols[j]:
                st.markdown(f"""
                <div class="card">
                    <div style="font-size:0.75rem; color:#034EA2; font-weight:700;">{item['category']} | {item['source']}</div>
                    <img src="{item['img']}" class="thumbnail">
                    <div style="font-weight:700; margin-bottom:5px;">{item['title_ko']}</div>
                    <div style="font-size:0.85rem; color:#555; height:60px; overflow:hidden;">{item['summary']}...</div>
                    <p style="font-size:0.75rem; margin-top:10px;"><a href="{item['link']}" target="_blank">ğŸ”— ì›ë³¸ ë³´ê¸°</a></p>
                </div>
                """, unsafe_allow_html=True)
                if st.button("ğŸ” ì „ëµ Deep-dive", key=f"btn_{item['id']}"):
                    model = get_ai_model()
                    with st.spinner("ë¶„ì„ ì¤‘..."):
                        res = model.generate_content(f"{st.session_state.settings['ai_prompt']}\në‚´ìš©: {item['title_en']}")
                        st.info(res.text)

    st.divider()

    # Sensing Stream (í•˜ë‹¨ ë¦¬ìŠ¤íŠ¸)
    for item in display_data[6:]:
        with st.container():
            c_img, c_txt = st.columns([1, 4])
            with c_img: st.image(item['img'])
            with c_txt:
                st.markdown(f"**{item['title_ko']}** ({item['date'].strftime('%m/%d')})")
                st.caption(f"Source: {item['source']} | AI Score: {item['score']}")
                st.write(f"{item['summary']}...")
                st.markdown(f"[ğŸ”— ì›ë³¸ ë§í¬]({item['link']})")
                if st.button("Quick View", key=f"q_{item['id']}"):
                    st.success(get_ai_model().generate_content(f"ìš”ì•½í•´ì¤˜: {item['title_en']}").text)
            st.markdown("---")
else:
    st.info("ì¡°ê±´ì— ë§ëŠ” í˜ì‹  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°” ì„¤ì •ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
