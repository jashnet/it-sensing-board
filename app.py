import streamlit as st
import feedparser
import google.generativeai as genai
from bs4 import BeautifulSoup
import json
import os
import re
from datetime import datetime, timedelta
import time
from deep_translator import GoogleTranslator
import requests
import hashlib
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==========================================
# ğŸ’ [GEMS ì„¤ì •] í˜ë¥´ì†Œë‚˜ ë° í”„ë¡¬í”„íŠ¸
# ==========================================
GEMS_PERSONA = """
ê·€í•˜ëŠ” ê¸€ë¡œë²Œ ë¹…í…Œí¬ ê¸°ì—…ì˜ 'ì°¨ì„¸ëŒ€ ê²½í—˜ê¸°íšíŒ€' ì†Œì† ìˆ˜ì„ ì „ëµ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
í–¥í›„ 2~3ë…„ ë‚´ ìƒìš©í™”ë  ì‹ ê·œ ìŠ¤ë§ˆíŠ¸ ë””ë°”ì´ìŠ¤ì™€ í˜ì‹ ì  UX/UIë¥¼ ê¸°íší•˜ê¸° ìœ„í•´ ì‹œì¥ì˜ 'ì´ˆê¸° ì‹œê·¸ë„'ì„ ì„¼ì‹±í•˜ëŠ” ê²ƒì´ ëª©ì ì…ë‹ˆë‹¤.

[ë¶„ì„ í•„ìˆ˜ í¬í•¨ í•­ëª©]
1. í˜ì‹ ì„±: ê¸°ì¡´ ì œí’ˆ ëŒ€ë¹„ ê²½í—˜ì˜ ë³€í™”ê°€ ì–¼ë§ˆë‚˜ í°ê°€?
2. íŒŒê¸‰ë ¥: ì „ì²´ ì—ì½”ì‹œìŠ¤í…œì— ì–´ë–¤ ë³€í™”ë¥¼ ì£¼ëŠ”ê°€?
3. ê¸°íšì  ê°€ì¹˜: ìš°ë¦¬ íŒ€ì˜ ì°¨ì„¸ëŒ€ ì œí’ˆ ê¸°íš(NOD í”„ë¡œì íŠ¸)ì— ì–´ë–¤ ì˜ê°ì„ ì£¼ëŠ”ê°€?
"""

DEFAULT_FILTER_PROMPT = """ê·€í•˜ëŠ” ì°¨ì„¸ëŒ€ê²½í—˜ê¸°íšíŒ€ì˜ 'NOD í”„ë¡œì íŠ¸' ì „ìš© ë‰´ìŠ¤ í•„í„°ë§ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë‰´ìŠ¤ì˜ ì œëª©ê³¼ ìš”ì•½ì„ ë³´ê³ , ìš°ë¦¬ íŒ€ì˜ ê¸°íš ë°©í–¥ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ 0~100ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

[í‰ê°€ ê¸°ì¤€]
- 90~100ì : ì™„ì „íˆ ìƒˆë¡œìš´ í¼íŒ©í„°, í˜ì‹ ì  UX, ìŠ¤ë§ˆíŠ¸ ë§/AR ê¸€ë˜ìŠ¤/ì‹ ê²½ ì¸í„°í˜ì´ìŠ¤(EMG) ë“± í•˜ë“œì›¨ì–´ ì‹œë„, ê³µê°„ ì»´í“¨íŒ…, ì—ì´ì „í‹± AI, ì£¼ìš” ë¹…í…Œí¬ì˜ í•µì‹¬ íŠ¹í—ˆ.
- 60~89ì : ê¸°ì¡´ í¼íŒ©í„°ì˜ ì„±ëŠ¥ í–¥ìƒ(AP, ë°°í„°ë¦¬ ë“±), ì¼ë°˜ì ì¸ ì›¨ì–´ëŸ¬ë¸”/ìŠ¤ë§ˆíŠ¸í° ì‹ ì œí’ˆ ì¶œì‹œ.
- 0~59ì : ë‹¨ìˆœ ë£¨ë¨¸, ì£¼ì‹/ì¬ë¬´ ë‰´ìŠ¤, ìš°ë¦¬ ê¸°íšê³¼ ë¬´ê´€í•œ ì¼ë°˜ IT ê°€ì‹­, ë‹¨ìˆœ S/W ì—…ë°ì´íŠ¸.

[í‰ê°€ ì˜ˆì‹œ (í•™ìŠµ ë°ì´í„°)]
ì˜ˆì‹œ 1) "ì• í”Œ, ì‹œì„  ì¶”ì ê³¼ EMG ë°´ë“œë¥¼ ê²°í•©í•œ ìƒˆë¡œìš´ AR ì¸í„°í˜ì´ìŠ¤ íŠ¹í—ˆ ë“±ë¡" -> 100
ì˜ˆì‹œ 2) "ì‚¼ì„±ì „ì ê°¤ëŸ­ì‹œ S26, ìŠ¤ëƒ…ë“œë˜ê³¤ 8 Gen 4 íƒ‘ì¬ë¡œ ê¸±ë²¤ì¹˜ ì ìˆ˜ ì†Œí­ ìƒìŠ¹" -> 65
ì˜ˆì‹œ 3) "í…ŒìŠ¬ë¼ ì£¼ê°€ 5% í•˜ë½, ë¨¸ìŠ¤í¬ì˜ ìƒˆë¡œìš´ íŠ¸ìœ— ì˜í–¥" -> 10
"""

# ==========================================
# ğŸ“‚ [ë°ì´í„° ê´€ë¦¬] ì±„ë„ íŒŒì¼ ì…ì¶œë ¥ ë¡œì§
# ==========================================
CHANNELS_FILE = "channels.json"

def load_channels_from_file():
    """channels.json íŒŒì¼ì—ì„œ ì±„ë„ ë¦¬ìŠ¤íŠ¸ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤."""
    if os.path.exists(CHANNELS_FILE):
        try:
            with open(CHANNELS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            st.error(f"ì±„ë„ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}
    return {} # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜

def save_channels_to_file(channels_data):
    """ì±„ë„ ë¦¬ìŠ¤íŠ¸ ë³€ê²½ì‚¬í•­ì„ channels.json íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        with open(CHANNELS_FILE, "w", encoding="utf-8") as f:
            json.dump(channels_data, f, ensure_ascii=False, indent=4)
    except Exception as e:
        st.error(f"ì±„ë„ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

# ==========================================
# âš™ï¸ [ì„¤ì • ê´€ë¦¬] ì‚¬ìš©ì ì„¤ì • ë¡œì§
# ==========================================
def load_user_settings(user_id):
    """ì‚¬ìš©ìë³„ ì„¤ì •(APIí‚¤, í”„ë¡¬í”„íŠ¸ ë“±)ì„ ë¡œë“œí•©ë‹ˆë‹¤. ì±„ë„ì€ ë³„ë„ íŒŒì¼ì—ì„œ ê´€ë¦¬í•©ë‹ˆë‹¤."""
    fn = f"nod_samsung_user_{user_id}.json"
    default_settings = {
        "api_key": "",
        "sensing_period": 3,
        "max_articles": 30,
        "filter_weight": 80,
        "filter_prompt": DEFAULT_FILTER_PROMPT,
        "ai_prompt": "ìœ„ ê¸°ì‚¬ë¥¼ ìš°ë¦¬ íŒ€ì˜ 'NOD í”„ë¡œì íŠ¸' ê´€ì ì—ì„œ ì‹¬ì¸µ ë¶„ì„í•´ì¤˜.",
        "category_active": {"Global Innovation": True, "China & East Asia": True, "Japan & Robotics": True}
    }
    
    # 1. ì‚¬ìš©ì ì„¤ì • íŒŒì¼ ë¡œë“œ
    if os.path.exists(fn):
        with open(fn, "r", encoding="utf-8") as f:
            saved = json.load(f)
            # ëˆ„ë½ëœ í‚¤ê°€ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ì›€
            for k, v in default_settings.items():
                if k not in saved: saved[k] = v
            return saved
    return default_settings

def save_user_settings(user_id, settings):
    with open(f"nod_samsung_user_{user_id}.json", "w", encoding="utf-8") as f:
        json.dump(settings, f, ensure_ascii=False, indent=4)

# ==========================================
# ğŸ§  [AI ì—”ì§„] Gemini API ì—°ë™ (ìœ ë£Œ Tier 1 ìµœì í™”)
# ==========================================
def get_ai_model(api_key, mode="filter"):
    # API í‚¤ê°€ ì—†ê±°ë‚˜ ë¹„ì •ìƒì ì´ë©´ ì‹¤í–‰ ì°¨ë‹¨
    if not api_key or len(api_key.strip()) < 10:
        return None
        
    try:
        genai.configure(api_key=api_key.strip())
        
        # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •] ê¼¬ë¦¬í‘œë¥¼ ëª¨ë‘ ë–¼ê³  ê°€ì¥ í‘œì¤€ì ì¸ ì •ì‹ ëª…ì¹­ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        MODEL_NAME = "gemini-1.5-flash"
        
        if mode == "analyze":
            return genai.GenerativeModel(MODEL_NAME, system_instruction=GEMS_PERSONA)
        else:
            return genai.GenerativeModel(MODEL_NAME)
    except: 
        return None

@st.cache_data(ttl=3600)
def safe_translate(text):
    if not text: return ""
    try: return GoogleTranslator(source='auto', target='ko').translate(text)
    except: return text

# ==========================================
# ğŸ“¡ [ìˆ˜ì§‘ ì—”ì§„] ë‰´ìŠ¤ í¬ë¡¤ë§ ë° í•„í„°ë§
# ==========================================
def fetch_raw_news(args):
    cat, f, limit = args
    articles = []
    try:
        d = feedparser.parse(f["url"])
        for entry in d.entries[:15]:
            dt = entry.get('published_parsed') or entry.get('updated_parsed')
            if not dt: continue
            p_date = datetime.fromtimestamp(time.mktime(dt))
            if p_date < limit: continue
            articles.append({
                "id": hashlib.md5(entry.link.encode()).hexdigest()[:12],
                "title_en": entry.title, "link": entry.link, "source": f["name"],
                "category": cat, "date_obj": p_date, "date": p_date.strftime("%Y.%m.%d"),
                "summary_en": BeautifulSoup(entry.get("summary", ""), "html.parser").get_text()[:300]
            })
    except: pass
    return articles

@st.cache_data(ttl=600) 
def get_filtered_news(settings, channels_data, _prompt, _weight):
    limit = datetime.now() - timedelta(days=settings["sensing_period"])
    
    # í™œì„±í™”ëœ ì±„ë„
