import streamlit as st
import feedparser
from google import genai
from google.genai import types
from bs4 import BeautifulSoup
import json
import os
import re
from datetime import datetime, timedelta
import time
from deep_translator import GoogleTranslator
import requests
import hashlib
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==========================================
# ğŸ’ [GEMS ì„¤ì •] í˜ë¥´ì†Œë‚˜ ë° í”„ë¡¬í”„íŠ¸
# ==========================================
GEMS_PERSONA = """
ê·€í•˜ëŠ” ì‚¼ì„±ì „ì 'ì°¨ì„¸ëŒ€ê²½í—˜ê¸°íšíŒ€' ì†Œì† ìµœê³  ìˆ˜ì¤€ì˜ ìˆ˜ì„ ì „ëµ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ìš°ë¦¬ì˜ ëª©í‘œëŠ” 2~3ë…„ ì´í›„ ìƒìš©í™”ë  ì‹ ê·œ ìŠ¤ë§ˆíŠ¸ ë””ë°”ì´ìŠ¤, í˜ì‹ ì  í¼íŒ©í„°, ê·¸ë¦¬ê³  AIê°€ ê²°í•©ëœ ì°¨ì„¸ëŒ€ UX/UIë¥¼ ì„ ì œì ìœ¼ë¡œ ë°œêµ´í•˜ëŠ” 'NOD í”„ë¡œì íŠ¸'ì˜ ì„±ê³µì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ê¸°ì‚¬ë¥¼ ë¶„ì„í•  ë•Œ ë‹¤ìŒ í•­ëª©ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ ì „ë¬¸ê°€ì ì¸ í†µì°°ë ¥ì„ ì œê³µí•˜ì„¸ìš”.

[ì‹¬ì¸µ ë¶„ì„ ë¦¬í¬íŠ¸ êµ¬ì¡°]
1. í•µì‹¬ ìš”ì•½ ë° ìˆ¨ì€ ì˜ë„: 
   - í‘œë©´ì ì¸ ë‰´ìŠ¤ ë‚´ìš©ì„ ë„˜ì–´, ì´ ê¸°ìˆ /ì œí’ˆì„ ë°œí‘œí•œ ê¸°ì—…(ë˜ëŠ” êµ­ê°€)ì˜ ì§„ì§œ ì „ëµì  ì˜ë„ê°€ ë¬´ì—‡ì¸ì§€ ë¶„ì„í•˜ì„¸ìš”.
2. íŒŒê¸‰ë ¥ ë° ìƒíƒœê³„ ì˜í–¥ (AI ê°€ì¤‘ì¹˜): 
   - ì´ ì†Œì‹ì´ ë‹¤ìˆ˜ì˜ ë””ë°”ì´ìŠ¤ ìƒíƒœê³„ë‚˜ ì†Œë¹„ìì˜ í–‰ë™ ì–‘ì‹(Behavior)ì— ì–´ë–¤ ê±°ëŒ€í•œ ë³€í™”ë¥¼ ê°€ì ¸ì˜¬ì§€ ë¶„ì„í•˜ì„¸ìš”. 
   - íŠ¹íˆ AI ë°œì „ì´ ìˆ˜ë°˜ëœ ê²½í—˜ì˜ ë³€í™”ë¼ë©´ ê·¸ í­ë°œë ¥ì„ ê°•ì¡°í•˜ì„¸ìš”.
3. NOD í”„ë¡œì íŠ¸(ì‚¼ì„±ì „ì)ë¥¼ ìœ„í•œ Implication:
   - ê²½ìŸì‚¬(Apple, Meta, OpenAI ë“± ë©”ì´ì € ë˜ëŠ” íŒŒê´´ì  í˜ì‹  ìŠ¤íƒ€íŠ¸ì—…/ì¤‘êµ­ ê¸°ì—…)ì˜ í–‰ë³´ê°€ ìš°ë¦¬ì—ê²Œ ë¯¸ì¹˜ëŠ” ìœ„í˜‘ê³¼ ê¸°íšŒëŠ” ë¬´ì—‡ì¸ê°€?
   - ì´ ì‹œê·¸ë„ì„ ë°”íƒ•ìœ¼ë¡œ ìš°ë¦¬ê°€ ë‹¹ì¥ ì—°êµ¬í•˜ê±°ë‚˜ ëŒ€ì‘í•´ì•¼ í•  ì œí’ˆì , UXì  ë°©í–¥ì„±ì€ ë¬´ì—‡ì¸ê°€?
"""

DEFAULT_FILTER_PROMPT = """ê·€í•˜ëŠ” ì‚¼ì„±ì „ì ì°¨ì„¸ëŒ€ê²½í—˜ê¸°íšíŒ€ì˜ ë‰´ìŠ¤ í•„í„°ë§ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë‰´ìŠ¤ì˜ ì œëª©ê³¼ ìš”ì•½ì„ ë³´ê³ , 2~3ë…„ ë’¤ ì¶œì‹œí•  'ì†Œë¹„ì ì¤‘ì‹¬ì˜ ì°¨ì„¸ëŒ€ ìŠ¤ë§ˆíŠ¸ ë””ë°”ì´ìŠ¤ ë° UX ê¸°íš'ì— ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œ ì‹œê·¸ë„ì¸ì§€ 0~100ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

[ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜ ê·œì¹™]
- +ê°€ì¤‘ì¹˜: ì œí’ˆ/ë””ë°”ì´ìŠ¤ ë˜ëŠ” ëª…í™•í•œ ì•±/ì„œë¹„ìŠ¤ ì¤‘ì‹¬ë‚´ìš©, AI ê¸°ìˆ ì´ ê²°í•©ëœ ê²½í—˜ ë³€í™”, ìƒíƒœê³„ ì „ë°˜ì„ í”ë“œëŠ” íŒŒê¸‰ë ¥, ì£¼ìš” ë¹…í…Œí¬(Apple, MS, Meta, Google, OpenAI ë“±)ì˜ í•µì‹¬ ë™í–¥, ë¯¸êµ­ì— ë„ì „í•˜ëŠ” ì¤‘êµ­ì˜ ê·¹ë‹¨ì  í•˜ë“œì›¨ì–´/AI ë³€í˜• ì‹œë„.
- -ê°ì /ë°°ì œ: ë‹¨ìˆœ ì‹¤ì /ì¬ë¬´ ë°œí‘œ, ì •ì±…/ë²•ë¥ /íŠ¹í—ˆ ì†Œì†¡, ê¸°ì—… ì¸ì‚¬ ë™ì •, ê´‘ê³ ì„± ì´ë²¤íŠ¸, ìˆœìˆ˜ B2B/ì‚°ì—…ìš© ê¸°ìˆ , ë‹¨ìˆœ ë°ì´í„° ê´€ë ¨ ì •ë³´
- ì¡°ê±´ë¶€ í—ˆìš©: ìë™ì°¨, ì´ë™ìˆ˜ë‹¨, ìŠ¤ë§ˆíŠ¸í™ˆ ë“±ì€ ê·¸ ìì²´ë¡œëŠ” ì ìˆ˜ê°€ ë‚®ìœ¼ë‚˜, 'ìŠ¤ë§ˆíŠ¸ ë””ë°”ì´ìŠ¤(í°, ì›¨ì–´ëŸ¬ë¸”)ì™€ì˜ ì—°ë™ì„ í†µí•œ ìƒˆë¡œìš´ UX ì°½ì¶œ' ë‚´ìš©ì´ë¼ë©´ ë†’ì€ ì ìˆ˜ë¥¼ ë¶€ì—¬í•¨.

[ì ìˆ˜ í‰ê°€ ê¸°ì¤€]
- 90-100 (í•µì‹¬ ì‹œê·¸ë„): ìŠ¤ë§ˆíŠ¸í°/ì›¨ì–´ëŸ¬ë¸”(ì›Œì¹˜, ë§, ê¸€ë˜ìŠ¤, ì´ì–´ë²„ì¦ˆ)/XR/ë¡œë´‡/AI Pin ë“±ì˜ ìƒˆë¡œìš´ í¼íŒ©í„° ë“±ì¥. ê¸°ì¡´ í•˜ë“œì›¨ì–´ì— ì‹ ê·œ ì„¼ì„œë¥¼ ê²°í•©í•œ í˜ì‹ . ë¹…í…Œí¬ë‚˜ íŒŒê´´ì  ìŠ¤íƒ€íŠ¸ì—…ì˜ íŒë„ë¥¼ ë°”ê¿€ AI ì„œë¹„ìŠ¤/UX ë°œí‘œ. íŒŒê¸‰ë ¥ì´ ì˜ˆìƒë˜ëŠ” ë©”ì´ì € í”Œë ˆì´ì–´ë“¤ì˜ ì‹ ì œí’ˆ ë£¨ë¨¸
- 70-90 (ì£¼ìš” ë™í–¥): ëª¨ë°”ì¼ ê¸°ê¸°ì™€ ì—°ë™ë˜ëŠ” ëª¨ë¹Œë¦¬í‹°/ìŠ¤ë§ˆíŠ¸í™ˆì˜ ìƒˆë¡œìš´ ê°€ì¹˜. ë©”ì´ì € í”Œë ˆì´ì–´ë“¤ì˜ ì¼ë°˜ì ì¸ ì˜ˆìƒë˜ëŠ” ì‹ ì œí’ˆ ë° ìŠ¤í™ ì—…ê·¸ë ˆì´ë“œ. ì†Œë¹„ì í–‰ë™ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ” ì‹ ê·œ ì•±/ì„œë¹„ìŠ¤. (ì¤‘êµ­ í•œì •) ìƒˆë¡œìš´ í˜•íƒœì˜ ìŠ¤ë§ˆíŠ¸ ë””ë°”ì´ìŠ¤ ë˜ëŠ” ê¸°ì¡´ ì œí’ˆì˜ í•˜ë“œì›¨ì–´ì  ë³€í˜• ì¶œì‹œ/ë°œí‘œ. (ì¤‘êµ­ í•œì •)ë¯¸êµ­ì— ë„ì „í•˜ê±°ë‚˜ ìœ„í˜‘í•˜ëŠ” AIê¸°ìˆ ë°œì „ì´ë‚˜ ê´€ë ¨ ì œí’ˆ/ì„œë¹„ìŠ¤ ë°œí‘œ.
- 50-70 (ì°¸ê³  ë™í–¥): ì‹ ê¸°í•œ IT ë””ë°”ì´ìŠ¤ ì œí’ˆ ë°œí‘œ ë° ì„œë¹„ìŠ¤ ì‹œë„, BigTechì™€ ê´€ë ¨ë˜ ì¸ìˆ˜/í•©ë³‘/íˆ¬ì
- 10-50 (ë…¸ì´ì¦ˆ): ì‚°ì—…ìš©(B2B) ì œí’ˆ/ë””ë°”ì´ìŠ¤/ë°œí‘œ, ìˆœìˆ˜ ìë™ì°¨ ìŠ¤í™ ë‰´ìŠ¤, ë‹¨ìˆœ ë§¤ì¶œ ë°œí‘œ, ë²•ì  ê·œì œ, ê´‘ê³ .

[ì¶œë ¥ í˜•ì‹ - ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•  ê²ƒ]
{
    "score": [0~100 ì‚¬ì´ì˜ ì •ìˆ˜],
    "insight_title": "[ì›ë¬¸ ë²ˆì—­ì´ ì•„ë‹Œ, ì°¨ì„¸ëŒ€ê²½í—˜ê¸°íšíŒ€ ê¸°íšì ê´€ì ì—ì„œ ë°”ë¼ë³¸ ì˜ë¯¸ í•´ì„ì„ ë‹´ì€ ë§¤ë ¥ì ì¸ 1ì¤„ ì¸ì‚¬ì´íŠ¸ ì œëª©(í•œêµ­ì–´)]",
    "core_summary": "[ì‹¤ì œ ê¸°ì‚¬ ë‚´ìš©ì´ ë¬´ì—‡ì¸ì§€ íŒ©íŠ¸ ìœ„ì£¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆëŠ” 2~3ì¤„ ìš”ì•½(í•œêµ­ì–´)]"
}
"""

# ==========================================
# ğŸ“‚ [ë°ì´í„° ê´€ë¦¬] ì±„ë„ íŒŒì¼ ì…ì¶œë ¥ ë¡œì§
# ==========================================
CHANNELS_FILE = "channels.json"

def load_channels_from_file():
    if os.path.exists(CHANNELS_FILE):
        try:
            with open(CHANNELS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            st.error(f"ì±„ë„ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}
    return {}

def save_channels_to_file(channels_data):
    try:
        with open(CHANNELS_FILE, "w", encoding="utf-8") as f:
            json.dump(channels_data, f, ensure_ascii=False, indent=4)
    except Exception as e:
        st.error(f"ì±„ë„ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

# ==========================================
# âš™ï¸ [ì„¤ì • ê´€ë¦¬] ì‚¬ìš©ì ì„¤ì • ë¡œì§
# ==========================================
def load_user_settings(user_id):
    fn = f"nod_samsung_user_{user_id}.json"
    default_settings = {
        "api_key": "",
        "sensing_period": 3,
        "max_articles": 60,
        "filter_weight": 70,
        "filter_prompt": DEFAULT_FILTER_PROMPT,
        "ai_prompt": "ìœ„ ê¸°ì‚¬ë¥¼ ìš°ë¦¬ íŒ€ì˜ 'NOD í”„ë¡œì íŠ¸' ê´€ì ì—ì„œ ì‹¬ì¸µ ë¶„ì„í•´ì¤˜.",
        "category_active": {"Global Innovation": True, "China & East Asia": True, "Japan & Robotics": True}
    }
    
    if os.path.exists(fn):
        with open(fn, "r", encoding="utf-8") as f:
            saved = json.load(f)
            for k, v in default_settings.items():
                if k not in saved: saved[k] = v
            return saved
    return default_settings

def save_user_settings(user_id, settings):
    with open(f"nod_samsung_user_{user_id}.json", "w", encoding="utf-8") as f:
        json.dump(settings, f, ensure_ascii=False, indent=4)

# ==========================================
# ğŸ§  [AI ì—”ì§„] Gemini API ì—°ë™
# ==========================================
def get_ai_client(api_key):
    if not api_key or len(api_key.strip()) < 10:
        return None
    try:
        return genai.Client(api_key=api_key.strip())
    except: 
        return None

@st.cache_data(ttl=3600)
def safe_translate(text):
    if not text: return ""
    try: return GoogleTranslator(source='auto', target='ko').translate(text)
    except: return text

# ==========================================
# ğŸ“¡ [ìˆ˜ì§‘ ì—”ì§„] ë‰´ìŠ¤ í¬ë¡¤ë§ ë° ì´ˆê³ ì† ë³‘ë ¬ í•„í„°ë§ (ìˆ˜ë™ ì‹¤í–‰ìš©)
# ==========================================
def fetch_raw_news(args):
    cat, f, limit = args
    articles = []
    try:
        d = feedparser.parse(f["url"])
        for entry in d.entries[:15]:
            dt = entry.get('published_parsed') or entry.get('updated_parsed')
            if not dt: continue
            p_date = datetime.fromtimestamp(time.mktime(dt))
            if p_date < limit: continue
            
            thumbnail = ""
            if 'media_content' in entry and len(entry.media_content) > 0:
                thumbnail = entry.media_content[0].get('url', '')
            elif 'media_thumbnail' in entry and len(entry.media_thumbnail) > 0:
                thumbnail = entry.media_thumbnail[0].get('url', '')
                
            articles.append({
                "id": hashlib.md5(entry.link.encode()).hexdigest()[:12],
                "title_en": entry.title, "link": entry.link, "source": f["name"],
                "category": cat, "date_obj": p_date, "date": p_date.strftime("%Y.%m.%d"),
                "summary_en": BeautifulSoup(entry.get("summary", ""), "html.parser").get_text()[:300],
                "thumbnail": thumbnail
            })
    except: pass
    return articles

def get_filtered_news(settings, channels_data, _prompt, _weight):
    limit = datetime.now() - timedelta(days=settings["sensing_period"])
    
    active_tasks = []
    for cat, feeds in channels_data.items():
        if settings["category_active"].get(cat, True):
            for f in feeds:
                if f.get("active", True):
                    active_tasks.append((cat, f, limit))
    
    if not active_tasks: return []

    raw_news = []
    with ThreadPoolExecutor(max_workers=40) as executor:
        futures = [executor.submit(fetch_raw_news, t) for t in active_tasks]
        for f in as_completed(futures): raw_news.extend(f.result())
    
    raw_news = sorted(raw_news, key=lambda x: x['date_obj'], reverse=True)[:settings["max_articles"]]
    
    client = get_ai_client(settings["api_key"])
    filtered_list = []
    
    if not client or not _prompt: 
        for item in raw_news:
            item["score"] = 100
            item["insight_title"] = safe_translate(item["title_en"])
            item["core_summary"] = safe_translate(item["summary_en"])
            filtered_list.append(item)
        return filtered_list

    pb = st.progress(0)
    st_text = st.empty()
    
    def ai_scoring_worker(item):
        try:
            score_query = f"{_prompt}\n\n[í‰ê°€ ëŒ€ìƒ]\nì œëª©: {item['title_en']}\nìš”ì•½: {item['summary_en'][:200]}"
            response = client.models.generate_content(
                model="gemini-2.5-flash",
                contents=score_query
            )
            res = response.text.strip()
            if res.startswith("```json"): res = res[7:-3].strip()
            elif res.startswith("```"): res = res[3:-3].strip()
            
            parsed_data = json.loads(res)
            item['score'] = int(parsed_data.get('score', 50))
            item['insight_title'] = parsed_data.get('insight_title') or safe_translate(item['title_en'])
            item['core_summary'] = parsed_data.get('core_summary') or safe_translate(item['summary_en'])
            
        except Exception:
            item['score'] = 50 
            item['insight_title'] = safe_translate(item['title_en'])
            item['core_summary'] = safe_translate(item['summary_en'])
        return item

    with ThreadPoolExecutor(max_workers=30) as executor:
        future_to_item = {executor.submit(ai_scoring_worker, item): item for item in raw_news}
        
        for i, future in enumerate(as_completed(future_to_item)):
            st_text.caption(f"âš¡ AI ìˆ˜ì„ ì „ëµê°€ê°€ ì‹¤ì‹œê°„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ({i+1}/{len(raw_news)})")
            pb.progress((i + 1) / len(raw_news))
            
            item = future.result()
            if item['score'] >= _weight:
                filtered_list.append(item)
                
    st_text.empty()
    pb.empty()
    return sorted(filtered_list, key=lambda x: x.get('score', 0), reverse=True)

# ==========================================
# ğŸ–¥ï¸ [UI] ë©”ì¸ í™”ë©´ ë Œë”ë§ (Top Picks + Stream)
# ==========================================
st.set_page_config(page_title="NGEPT Strategy Hub", layout="wide")

st.markdown("""<style>
    body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; }
    
    /* --- Top Picks ì¹´ë“œ ìŠ¤íƒ€ì¼ --- */
    .top-pick-card {
        position: relative; border-radius: 16px; overflow: hidden;
        aspect-ratio: 4/3; margin-bottom: 20px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        transition: transform 0.2s;
    }
    .top-pick-card:hover { transform: translateY(-3px); }
    .top-pick-bg { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; z-index: 1; }
    .top-pick-overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: linear-gradient(to bottom, rgba(0,0,0,0.1) 0%, rgba(0,0,0,0.7) 100%); z-index: 2; }
    .top-pick-content { position: absolute; bottom: 0; left: 0; width: 100%; padding: 20px; z-index: 3; color: white; }
    .top-pick-score { display: inline-block; padding: 4px 10px; background: #0095f6; color: white; border-radius: 12px; font-size: 0.75rem; font-weight: 700; margin-bottom: 8px; }
    .top-pick-title { font-size: 1.3rem; font-weight: 800; line-height: 1.3; margin-bottom: 8px; text-shadow: 0 1px 3px rgba(0,0,0,0.5); }
    .top-pick-source { font-size: 0.85rem; opacity: 0.9; }

    /* --- Sensing Stream ì¹´ë“œ ìŠ¤íƒ€ì¼ --- */
    .stream-card { background: #ffffff; border: 1px solid #dbdbdb; border-radius: 12px; margin-bottom: 30px; overflow: hidden; }
    .stream-header { padding: 12px 16px; display: flex; justify-content: space-between; align-items: center; border-bottom: 1px solid #efefef; }
    .source-badge { display: flex; align-items: center; gap: 10px; }
    .source-icon { width: 28px; height: 28px; background: #f0f2f5; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 14px; }
    .source-name { font-weight: 600; font-size: 0.9rem; color: #262626; }
    .stream-score { background-color: #E3F2FD; color: #1565C0; padding: 4px 10px; border-radius: 12px; font-size: 0.75rem; font-weight: 700; }
    .stream-img { width: 100%; aspect-ratio: 16/9; object-fit: cover; display: block; }
    .stream-body { padding: 16px; }
    .stream-title { font-weight: 700; font-size: 1.05rem; line-height: 1.4; color: #262626; margin-bottom: 10px; }
    .stream-text { font-size: 0.9rem; color: #444; line-height: 1.5; margin-bottom: 16px; }
    .read-more { color: #0095f6; font-weight: 600; text-decoration: none; font-size: 0.9rem; }
    
    .section-header { font-size: 1.5rem; font-weight: 700; margin: 30px 0 20px 0; display: flex; align-items: center; gap: 10px; }
</style>""", unsafe_allow_html=True)

if "channels" not in st.session_state:
    st.session_state.channels = load_channels_from_file()

with st.sidebar:
    st.title("ğŸ‘¤ NOD Leader Profile")
    u_id = st.radio("ì‚¬ìš©ì í”„ë¡œí•„", ["1", "2", "3", "4"], horizontal=True)

    if "current_user" not in st.session_state or st.session_state.current_user != u_id:
        st.session_state.current_user = u_id
        st.session_state.settings = load_user_settings(u_id)
        st.session_state.channels = load_channels_from_file()
        st.rerun()

    st.divider()
    
    # ğŸ’¡ [ë³´ì•ˆ ë° í¸ì˜ì„± ê°•í™”] Streamlit Secrets ìë™ ì—°ë™ ë¡œì§
    if "GEMINI_API_KEY" in st.secrets:
        st.session_state.settings["api_key"] = st.secrets["GEMINI_API_KEY"]
        st.success("ğŸ”’ ì‹œìŠ¤í…œ API Key ìë™ ì—°ë™ ì™„ë£Œ")
    else:
        curr_key = st.session_state.settings.get("api_key", "").strip()
        if not st.session_state.get("editing_key", False) and curr_key:
            st.success("âœ… ìˆ˜ë™ API Key ì—°ë™ë¨")
            if st.button("ğŸ”‘ í‚¤ ë³€ê²½"):
                st.session_state.editing_key = True; st.rerun()
        else:
            new_key = st.text_input("Gemini API Key", value=curr_key, type="password")
            if st.button("ğŸ’¾ ì €ì¥"):
                st.session_state.settings["api_key"] = new_key
                save_user_settings(u_id, st.session_state.settings)
                st.session_state.editing_key = False; st.rerun()

    st.divider()
    
    st.subheader("ğŸ“‚ ì±„ë„ ê´€ë¦¬ (Channels.json)")
    
    for cat in st.session_state.channels.keys():
        if cat not in st.session_state.settings["category_active"]:
            st.session_state.settings["category_active"][cat] = True

    for cat in list(st.session_state.channels.keys()):
        is_active = st.session_state.settings["category_active"].get(cat, True)
        st.session_state.settings["category_active"][cat] = st.toggle(f"{cat} ({len(st.session_state.channels[cat])})", value=is_active)
        
        if st.session_state.settings["category_active"][cat]:
            with st.expander(f"ğŸ“Œ {cat} ëª©ë¡ í¸ì§‘"):
                with st.form(f"add_{cat}", clear_on_submit=True):
                    c1, c2 = st.columns([2, 3])
                    new_name = c1.text_input("ì´ë¦„", placeholder="ì˜ˆ: Verge")
                    new_url = c2.text_input("RSS URL", placeholder="https://...")
                    if st.form_submit_button("â• ì±„ë„ ì¶”ê°€"):
                        if new_name and new_url:
                            st.session_state.channels[cat].append({"name": new_name, "url": new_url, "active": True})
                            save_channels_to_file(st.session_state.channels)
                            st.rerun()
                
                for idx, f in enumerate(st.session_state.channels[cat]):
                    c1, c2 = st.columns([4, 1])
                    prev_state = f.get("active", True)
                    new_state = c1.checkbox(f["name"], value=prev_state, key=f"cb_{cat}_{idx}")
                    if prev_state != new_state:
                        f["active"] = new_state
                        save_channels_to_file(st.session_state.channels)
                    
                    if c2.button("ğŸ—‘ï¸", key=f"del_{cat}_{idx}"):
                        st.session_state.channels[cat].pop(idx)
                        save_channels_to_file(st.session_state.channels)
                        st.rerun()

    st.divider()

    st.subheader("ğŸ›ï¸ ê¸°ë³¸ í•„í„° ì„¤ì •")
    f_weight = st.slider("ğŸ¯ ìµœì†Œ ë§¤ì¹­ ì ìˆ˜", 0, 100, st.session_state.settings["filter_weight"])
    st.session_state.settings["sensing_period"] = st.slider("ìµœê·¼ Nì¼ ê¸°ì‚¬ë§Œ ìˆ˜ì§‘", 1, 30, st.session_state.settings["sensing_period"])
    st.session_state.settings["max_articles"] = st.slider("ìµœëŒ€ ë¶„ì„ ê¸°ì‚¬ ìˆ˜", 30, 100, st.session_state.settings["max_articles"])

    with st.expander("âš™ï¸ ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì„¤ì •", expanded=False):
        f_prompt = st.text_area("ğŸ” í•„í„° í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥)", value=st.session_state.settings["filter_prompt"], height=200)
        st.session_state.settings["ai_prompt"] = st.text_area("ğŸ“ ë¶„ì„ í”„ë¡¬í”„íŠ¸", value=st.session_state.settings["ai_prompt"], height=100)

    # ğŸ’¡ [í•˜ì´ë¸Œë¦¬ë“œ ì—”ì§„] ìˆ˜ë™ ì‹¤í–‰ ë° ìë™ ë³µê·€ ë²„íŠ¼
    st.info("ğŸ’¡ í‰ì†Œì—” ì•„ì¹¨ ìë™ ìˆ˜ì§‘ë³¸ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì„¤ì •ì„ ë³€ê²½í–ˆê±°ë‚˜ ë‹¹ì¥ ìµœì‹  ë‰´ìŠ¤ë¥¼ ë³´ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
    if st.button("ğŸš€ ì‹¤ì‹œê°„ ìˆ˜ë™ ì„¼ì‹± ì‹œì‘", use_container_width=True, type="primary"):
        st.session_state.settings["filter_prompt"] = f_prompt
        st.session_state.settings["filter_weight"] = f_weight
        save_user_settings(u_id, st.session_state.settings)
        
        with st.spinner("ğŸ“¡ í˜„ì¬ ê¸°ì¤€ ìµœì‹  ê¸°ì‚¬ ìˆ˜ì§‘ ë° AI ë¶„ì„ ì¤‘... (ì•½ 30ì´ˆ ì†Œìš”)"):
            live_result = get_filtered_news(
                st.session_state.settings, 
                st.session_state.channels, 
                st.session_state.settings["filter_prompt"], 
                st.session_state.settings["filter_weight"]
            )
            st.session_state.manual_news = live_result # ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
            st.success("âœ… ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
            time.sleep(1)
            st.rerun()
            
    if st.button("â™»ï¸ ì›ë˜ ì•„ì¹¨(ìë™) ë²„ì „ìœ¼ë¡œ ëŒì•„ê°€ê¸°", use_container_width=True):
        if "manual_news" in st.session_state:
            del st.session_state["manual_news"]
        st.rerun()
        
    st.divider()
    
    if st.button("ğŸ” ë‚´ API í‚¤ í—ˆìš© ëª¨ë¸ í™•ì¸í•˜ê¸°"):
        test_key = st.session_state.settings.get("api_key", "").strip()
        if not test_key:
            st.error("âš ï¸ ìœ„ì ¯ì—ì„œ API Keyë¥¼ ë¨¼ì € ì…ë ¥í•˜ê³  [ğŸ’¾ ì €ì¥]ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        else:
            try:
                temp_client = get_ai_client(test_key)
                models = temp_client.models.list()
                model_names = [m.name for m in models]
                st.success(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡: {model_names}")
            except Exception as e:
                st.error(f"ğŸš¨ ì¡°íšŒ ì‹¤íŒ¨: {e}")

# ==========================================
# 2. ë©”ì¸ ì»¨í…ì¸  ì˜ì—­
# ==========================================
st.markdown("<h1 style='text-align:center;'>NOD Strategy Hub</h1>", unsafe_allow_html=True)
st.caption(f"<div style='text-align:center;'>ì°¨ì„¸ëŒ€ ê²½í—˜ê¸°íšíŒ€ì„ ìœ„í•œ Gems í†µí•© ì¸ì‚¬ì´íŠ¸ ë³´ë“œ</div><br>", unsafe_allow_html=True)

# ğŸ’¡ [í•˜ì´ë¸Œë¦¬ë“œ ë¡œë”© ë¡œì§] ìˆ˜ë™ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìš°ì„  í‘œì‹œ, ì—†ìœ¼ë©´ JSON ì½ê¸°
news_list = []
if "manual_news" in st.session_state:
    news_list = st.session_state.manual_news
    st.success("ğŸ“¡ **Live Mode:** ìˆ˜ë™ìœ¼ë¡œ ì‹¤ì‹œê°„ ìˆ˜ì§‘í•œ ë‰´ìŠ¤ë¥¼ ë³´ê³  ê³„ì‹­ë‹ˆë‹¤.")
elif os.path.exists("today_news.json"):
    try:
        with open("today_news.json", "r", encoding="utf-8") as f:
            news_list = json.load(f)
        st.info("ğŸ•’ **Batch Mode:** ë§¤ì¼ ì•„ì¹¨ ìë™ ìˆ˜ì§‘ëœ ë°ì¼ë¦¬ ë¸Œë¦¬í•‘ì…ë‹ˆë‹¤.")
    except Exception as e:
        st.error("ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì½ì–´ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

if not news_list:
    st.warning("ğŸ“­ ë³´ì—¬ì¤„ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢Œì¸¡ì˜ [ğŸš€ ì‹¤ì‹œê°„ ìˆ˜ë™ ì„¼ì‹± ì‹œì‘] ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”!")
else:
    top_picks = news_list[:6]
    stream_news = news_list[6:]

    # ==========================
    # ğŸ† Section 1: Today's Top Picks
    # ==========================
    st.markdown("<div class='section-header'>ğŸ† Today's Top Picks</div>", unsafe_allow_html=True)
    
    top_cols = st.columns(3)
    for i, item in enumerate(top_picks):
        with top_cols[i % 3]:
            img_src = item.get('thumbnail') if item.get('thumbnail') else f"https://s.wordpress.com/mshots/v1/{item['link']}?w=800"
            title_text = item.get('insight_title', item['title_en'])
            
            html_card = f"""
            <a href="{item['link']}" target="_blank" style="text-decoration:none;">
                <div class="top-pick-card">
                    <img src="{img_src}" class="top-pick-bg" loading="lazy" onerror="this.src='https://via.placeholder.com/800x600/1a1a1a/ffffff?text=NOD+Insight';">
                    <div class="top-pick-overlay"></div>
                    <div class="top-pick-content">
                        <span class="top-pick-score">MATCH {item['score']}%</span>
                        <div class="top-pick-title">{title_text}</div>
                        <div class="top-pick-source">ğŸ“° {item['source']}</div>
                    </div>
                </div>
            </a>
            """
            st.markdown(html_card, unsafe_allow_html=True)

    # ==========================
    # ğŸŒŠ Section 2: Sensing Stream
    # ==========================
    st.divider()
    st.markdown("<div class='section-header'>ğŸŒŠ Sensing Stream</div>", unsafe_allow_html=True)

    stream_cols = st.columns(3)
    for i, item in enumerate(stream_news):
        with stream_cols[i % 3]:
            img_src = item.get('thumbnail') if item.get('thumbnail') else f"https://s.wordpress.com/mshots/v1/{item['link']}?w=600"
            title_text = item.get('insight_title', item['title_en'])
            summary_text = item.get('core_summary', item.get('summary_ko', ''))
            
            html_card = f"""
            <div class="stream-card">
                <div class="stream-header">
                    <div class="source-badge">
                        <div class="source-icon">ğŸ“°</div>
                        <div class="source-name">{item['source']}</div>
                    </div>
                    <span class="stream-score">MATCH {item['score']}%</span>
                </div>
                <img src="{img_src}" class="stream-img" loading="lazy" onerror="this.src='https://via.placeholder.com/600x338?text=No+Image';">
                <div class="stream-body">
                    <div class="stream-title">ğŸ’¡ {title_text}</div>
                    <div class="stream-text">{summary_text}</div>
                    <a href="{item['link']}" target="_blank" class="read-more">ì›ë¬¸ ê¸°ì‚¬ ì½ê¸° â†—</a>
                </div>
            </div>
            """
            st.markdown(html_card, unsafe_allow_html=True)
            
            if st.button("ğŸ” Gems Deep Analysis", key=f"btn_{item['id']}", use_container_width=True):
                current_api_key = st.session_state.settings.get("api_key", "").strip()
                if not current_api_key:
                    st.warning("âš ï¸ API Keyë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                else:
                    client = get_ai_client(current_api_key)
                    if client:
                        with st.spinner("ğŸ’ ìˆ˜ì„ ì „ëµê°€ê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                            try:
                                config = types.GenerateContentConfig(system_instruction=GEMS_PERSONA)
                                prompt = f"{st.session_state.settings['ai_prompt']}\n\n[ê¸°ì‚¬]\nì œëª©: {item['title_en']}\nìš”ì•½: {item['summary_en']}"
                                response = client.models.generate_content(model="gemini-2.5-flash", contents=prompt, config=config)
                                st.info(response.text)
                            except Exception as e:
                                st.error(f"ğŸš¨ ë¶„ì„ ì˜¤ë¥˜: {e}")
