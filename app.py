import streamlit as st
import feedparser
import google.generativeai as genai
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime, timedelta
import time
from deep_translator import GoogleTranslator

# --- 1. ì„¤ì • ì €ì¥ ë° ë¡œë“œ ---
SETTINGS_FILE = "nod_pro_settings.json"

def load_settings():
    if os.path.exists(SETTINGS_FILE):
        try:
            with open(SETTINGS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except: return default_settings()
    return default_settings()

def default_settings():
    return {
        "api_key": "",
        "sensing_period": 7,
        # í•µì‹¬: AIê°€ ë‰´ìŠ¤ë¥¼ í†µê³¼ì‹œí‚¬ì§€ ê²°ì •í•˜ëŠ” ê¸°ì¤€
        "filter_prompt": "ì°¨ì„¸ëŒ€ ê²½í—˜ ê¸°íš(Next-Gen Experience) ë° NOD í”„ë¡œì íŠ¸ì— ì˜ê°ì„ ì¤„ ìˆ˜ ìˆëŠ”ê°€? íŠ¹íˆ AI í•˜ë“œì›¨ì–´, RTOS ì›Œì¹˜, ìŠ¤í¬ë¦° ì—†ëŠ” í¬ì¼“ ì»´í“¨íŒ…, í˜ì‹ ì  UX ì‹œë„ì— í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ë§Œ 'True'ë¡œ íŒë³„í•˜ë¼. ì¼ë°˜ì ì¸ ëŒ€ê¸°ì—… ì£¼ê°€ë‚˜ ë‹¨ìˆœ SW ì—…ë°ì´íŠ¸ëŠ” 'False'ë¡œ íŒë³„í•˜ë¼.",
        "ai_analysis_prompt": "ì´ ì œí’ˆ/ì„œë¹„ìŠ¤ì˜ UX ë³€ê³¡ì ì„ ë¶„ì„í•˜ê³ , ìš°ë¦¬ íŒ€ì˜ ì°¨ì„¸ëŒ€ ë””ë°”ì´ìŠ¤ ì „ëµì— ì´ì‹í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ì•„ì´ë””ì–´ 2ê°œë¥¼ ì œì•ˆí•˜ë¼.",
        "channels": {
            "ê¸€ë¡œë²Œ (Tech/Design)": [
                {"name": "The Verge", "url": "https://www.theverge.com/rss/index.xml", "active": True},
                {"name": "Wired", "url": "https://www.wired.com/feed/rss", "active": True},
                {"name": "Yanko Design", "url": "https://www.yankodesign.com/feed/", "active": True},
                {"name": "Product Hunt", "url": "https://www.producthunt.com/feed", "active": True},
                {"name": "TechCrunch", "url": "https://techcrunch.com/feed/", "active": True}
            ],
            "ì¤‘êµ­ (AI/Hardware)": [
                {"name": "36Kr", "url": "https://36kr.com/feed", "active": True},
                {"name": "TechNode", "url": "https://technode.com/feed/", "active": True},
                {"name": "Gizmochina", "url": "https://www.gizmochina.com/feed/", "active": True}
            ],
            "ì¼ë³¸ (Innovation)": [
                {"name": "The Bridge JP", "url": "https://thebridge.jp/feed", "active": True},
                {"name": "ITmedia News", "url": "https://rss.itmedia.co.jp/rss/2.0/news_bursts.xml", "active": True},
                {"name": "Gizmodo JP", "url": "https://www.gizmodo.jp/index.xml", "active": True}
            ]
        }
    }

def save_settings(settings):
    with open(SETTINGS_FILE, "w", encoding="utf-8") as f:
        json.dump(settings, f, ensure_ascii=False, indent=4)

if "settings" not in st.session_state:
    st.session_state.settings = load_settings()

# --- 2. UI ìŠ¤íƒ€ì¼ ---
st.set_page_config(page_title="NOD Intelligence Hub", layout="wide")
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;700&display=swap');
    html, body, [class*="css"] { font-family: 'Noto Sans KR', sans-serif; background-color: #f0f2f5; }
    .stAlert { border-radius: 12px; }
    .card {
        background: white; padding: 24px; border-radius: 20px;
        box-shadow: 0 4px 20px rgba(0,0,0,0.08); margin-bottom: 24px;
        border: 1px solid #eef0f2; height: 100%;
    }
    .card-title { font-size: 1.1rem; font-weight: 700; color: #1c1e21; margin-bottom: 12px; line-height: 1.5; }
    .card-summary { font-size: 0.9rem; color: #4b4f56; line-height: 1.6; margin-bottom: 15px; }
    .thumbnail { width: 100%; height: 200px; object-fit: cover; border-radius: 12px; margin-bottom: 16px; }
    .badge { background: #e7f3ff; color: #1877f2; padding: 4px 10px; border-radius: 6px; font-size: 0.75rem; font-weight: 700; margin-bottom: 10px; display: inline-block; }
</style>
""", unsafe_allow_html=True)

# --- 3. í•µì‹¬ ë¡œì§: AI í•„í„°ë§ ë° ìˆ˜ì§‘ ---
def get_ai_model():
    if not st.session_state.settings["api_key"]: return None
    genai.configure(api_key=st.session_state.settings["api_key"])
    for name in ['gemini-1.5-flash', 'gemini-1.5-flash-latest']:
        try:
            model = genai.GenerativeModel(name)
            return model
        except: continue
    return None

def ai_filter_news(news_list, model):
    if not model: return news_list
    
    filtered = []
    st.write(f"ğŸ”„ AIê°€ {len(news_list)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ì „ëµì  ê¸°ì¤€ìœ¼ë¡œ ê²€í†  ì¤‘...")
    
    for item in news_list:
        prompt = f"ê¸°ì¤€: {st.session_state.settings['filter_prompt']}\n\në‚´ìš©: {item['title']}\nê²°ê³¼ë¥¼ ë”± í•œ ë‹¨ì–´(True ë˜ëŠ” False)ë¡œë§Œ ë‹µí•˜ë¼."
        try:
            response = model.generate_content(prompt)
            if "true" in response.text.lower():
                filtered.append(item)
        except:
            filtered.append(item) # ì—ëŸ¬ ì‹œ ì¼ë‹¨ í¬í•¨
    return filtered

@st.cache_data(ttl=3600)
def fetch_sensing_data():
    all_data = []
    limit = datetime.now() - timedelta(days=st.session_state.settings["sensing_period"])
    translator = GoogleTranslator(source='auto', target='ko')

    for cat, feeds in st.session_state.settings["channels"].items():
        for f in feeds:
            if not f["active"]: continue
            d = feedparser.parse(f["url"])
            for entry in d.entries[:8]:
                try:
                    p_date = datetime.fromtimestamp(time.mktime(entry.published_parsed))
                    if p_date < limit: continue
                    
                    # ì¸ë„¤ì¼ ì¶”ì¶œ
                    img = "https://via.placeholder.com/400x250?text=Sensing+Image"
                    if 'media_content' in entry: img = entry.media_content[0]['url']
                    elif 'description' in entry:
                        soup = BeautifulSoup(entry.description, "html.parser")
                        tag = soup.find("img")
                        if tag: img = tag["src"]

                    all_data.append({
                        "title": translator.translate(entry.title),
                        "summary": translator.translate(BeautifulSoup(entry.get("summary", ""), "html.parser").get_text()[:200]),
                        "img": img, "source": f["name"], "date": p_date.strftime("%m/%d"), "link": entry.link
                    })
                except: continue
    return all_data

# --- 4. ë©”ì¸ UI ---
with st.sidebar:
    st.title("âš™ï¸ NOD Config")
    if not st.session_state.settings["api_key"]:
        key = st.text_input("Gemini API Key", type="password")
        if st.button("ì—°ê²° ë° ì €ì¥"):
            st.session_state.settings["api_key"] = key
            save_settings(st.session_state.settings)
            st.rerun()
    else:
        st.success("âœ… AI ì—°ê²° ìƒíƒœ ì–‘í˜¸")
        if st.button("Key ì¬ì„¤ì •"):
            st.session_state.settings["api_key"] = ""
            st.rerun()

    st.divider()
    st.subheader("ğŸ“ ì±„ë„ ê·¸ë£¹")
    for cat, feeds in st.session_state.settings["channels"].items():
        with st.expander(f"{cat}"):
            for f in feeds:
                f["active"] = st.checkbox(f["name"], value=f["active"])
            if st.button(f"â• {cat} ì¶”ê°€", key=f"add_{cat}"):
                st.session_state.adding = cat

    st.divider()
    with st.expander("ğŸ“ AI ì „ëµ í•„í„°/í”„ë¡¬í”„íŠ¸ ì„¤ì •"):
        st.session_state.settings["filter_prompt"] = st.text_area("1. ë‰´ìŠ¤ í•„í„°ë§ ê¸°ì¤€", value=st.session_state.settings["filter_prompt"], height=150)
        st.session_state.settings["ai_analysis_prompt"] = st.text_area("2. Deep-dive ë¶„ì„ ê°€ì´ë“œ", value=st.session_state.settings["ai_analysis_prompt"], height=150)
        if st.button("ì„¤ì • ì €ì¥"):
            save_settings(st.session_state.settings)
            st.toast("ì „ëµ ê¸°ì¤€ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")

# --- 5. ëŒ€ì‹œë³´ë“œ ì¶œë ¥ ---
st.title("ğŸš€ NOD Intelligence Dashboard")
raw_news = fetch_sensing_data()

model = get_ai_model()
if model and raw_news:
    # í•„í„°ë§ ìˆ˜í–‰
    filtered_news = ai_filter_news(raw_news, model)
else:
    filtered_news = raw_news

if filtered_news:
    st.subheader(f"ğŸ’¡ AIê°€ ì—„ì„ í•œ {len(filtered_news)}ê°œì˜ í•µì‹¬ ì‹ í˜¸")
    
    # 3ì—´ ê·¸ë¦¬ë“œ ë°°ì¹˜
    grid = [filtered_news[i:i + 3] for i in range(0, len(filtered_news), 3)]
    for row in grid:
        cols = st.columns(3)
        for i, item in enumerate(row):
            with cols[i]:
                st.markdown(f"""
                <div class="card">
                    <div class="badge">{item['source']}</div>
                    <img src="{item['img']}" class="thumbnail">
                    <div class="card-title">{item['title']}</div>
                    <div class="card-summary">{item['summary']}...</div>
                    <p style="font-size:0.8rem; color:#888;">{item['date']} | <a href="{item['link']}" target="_blank">ì›ë³¸ë³´ê¸°</a></p>
                </div>
                """, unsafe_allow_html=True)
                if st.button("ğŸ” ì „ëµì  Deep-dive", key=f"dd_{item['link'][-10:]}"):
                    with st.spinner("AI ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."):
                        analysis = model.generate_content(f"{st.session_state.settings['ai_analysis_prompt']}\n\në‰´ìŠ¤: {item['title']}\n{item['summary']}")
                        st.info(analysis.text)
else:
    st.info("í˜„ì¬ í•„í„°ë§ ì¡°ê±´ì— ë§ëŠ” í˜ì‹ ì ì¸ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„ì´ë‚˜ ì±„ë„ì„ ëŠ˜ë ¤ë³´ì„¸ìš”.")
