import streamlit as st
import feedparser
import google.generativeai as genai
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime, timedelta
import time
from deep_translator import GoogleTranslator

# --- 1. ì„¤ì • ë° ë¡œë“œ ---
SETTINGS_FILE = "nod_pro_settings_v2.json"

def load_settings():
    if os.path.exists(SETTINGS_FILE):
        try:
            with open(SETTINGS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except: return default_settings()
    return default_settings()

def default_settings():
    return {
        "api_key": "",
        "sensing_period": 14,
        "filter_prompt": "ì°¨ì„¸ëŒ€ ê²½í—˜ ê¸°íš(Next-Gen Experience) ë° NOD í”„ë¡œì íŠ¸ì— ì˜ê°ì„ ì¤„ ìˆ˜ ìˆëŠ”ê°€? íŠ¹íˆ AI í•˜ë“œì›¨ì–´, RTOS ì›Œì¹˜, ìŠ¤í¬ë¦° ì—†ëŠ” í¬ì¼“ ì»´í“¨íŒ…, í˜ì‹ ì  UX ì‹œë„ì— í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ë§Œ 'True'ë¡œ íŒë³„í•˜ë¼.",
        "ai_analysis_prompt": "ì´ ì œí’ˆ/ì„œë¹„ìŠ¤ì˜ UX ë³€ê³¡ì ì„ ë¶„ì„í•˜ê³ , ìš°ë¦¬ íŒ€ì˜ ì°¨ì„¸ëŒ€ ë””ë°”ì´ìŠ¤ ì „ëµì— ì´ì‹í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ì•„ì´ë””ì–´ 2ê°œë¥¼ ì œì•ˆí•˜ë¼.",
        "channels": {
            "ê¸€ë¡œë²Œ (Tech/Design)": [
                {"name": "The Verge", "url": "https://www.theverge.com/rss/index.xml", "active": True},
                {"name": "Wired", "url": "https://www.wired.com/feed/rss", "active": True},
                {"name": "Yanko Design", "url": "https://www.yankodesign.com/feed/", "active": True},
                {"name": "Product Hunt", "url": "https://www.producthunt.com/feed", "active": True}
            ],
            "ì¤‘êµ­ (AI/Hardware)": [
                {"name": "36Kr", "url": "https://36kr.com/feed", "active": True},
                {"name": "TechNode", "url": "https://technode.com/feed/", "active": True}
            ],
            "ì¼ë³¸ (Innovation)": [
                {"name": "The Bridge JP", "url": "https://thebridge.jp/feed", "active": True},
                {"name": "ITmedia News", "url": "https://rss.itmedia.co.jp/rss/2.0/news_bursts.xml", "active": True}
            ]
        }
    }

def save_settings(settings):
    with open(SETTINGS_FILE, "w", encoding="utf-8") as f:
        json.dump(settings, f, ensure_ascii=False, indent=4)

if "settings" not in st.session_state:
    st.session_state.settings = load_settings()

# --- 2. ê°•í™”ëœ ì¸ë„¤ì¼ ì¶”ì¶œ ë¡œì§ (The Image Rescue) ---
def get_robust_thumbnail(entry):
    """5ë‹¨ê³„ì— ê±¸ì³ ì´ë¯¸ì§€ë¥¼ íƒìƒ‰í•˜ì—¬ ìµœì„ ì˜ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # 1ë‹¨ê³„: í‘œì¤€ media_content íƒœê·¸ í™•ì¸
    if 'media_content' in entry and len(entry.media_content) > 0:
        return entry.media_content[0]['url']
    
    # 2ë‹¨ê³„: media_thumbnail ë˜ëŠ” media_image í™•ì¸
    if 'media_thumbnail' in entry and len(entry.media_thumbnail) > 0:
        return entry.media_thumbnail[0]['url']
    if 'media_image' in entry:
        return entry.media_image

    # 3ë‹¨ê³„: enclosure(íŒŒì¼ ì²¨ë¶€) í™•ì¸
    if 'enclosures' in entry and len(entry.enclosures) > 0:
        for enc in entry.enclosures:
            if enc.get('type', '').startswith('image/'):
                return enc.get('href')

    # 4ë‹¨ê³„: HTML ë³¸ë¬¸(summary ë˜ëŠ” description) ë‚´ë¶€ <img> íƒœê·¸ íŒŒì‹±
    content_html = entry.get("summary", "") or entry.get("description", "")
    if content_html:
        soup = BeautifulSoup(content_html, "html.parser")
        img_tag = soup.find("img")
        if img_tag and img_tag.get("src"):
            src = img_tag["src"]
            # 1x1 í”½ì…€ ê°™ì€ íŠ¸ë˜í‚¹ìš© ì´ë¯¸ì§€ëŠ” ì œì™¸
            if "tracker" not in src and "stat" not in src:
                return src

    # 5ë‹¨ê³„: ìµœì¢… ì‹¤íŒ¨ ì‹œ - ê¹”ë”í•œ í…Œí¬ ë””ìì¸ í”Œë ˆì´ìŠ¤í™€ë” ë°˜í™˜
    # (ì œëª©ì˜ ì²« ê¸€ìë¥¼ ë”°ì„œ ìƒì„±í•˜ëŠ” placeholder ì„œë¹„ìŠ¤ ì´ìš©)
    return f"https://via.placeholder.com/600x400/1a73e8/ffffff?text=NOD+Sensing"

# --- 3. UI ë° ìŠ¤íƒ€ì¼ ---
st.set_page_config(page_title="NOD Intelligence Hub", layout="wide")
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;700&display=swap');
    html, body, [class*="css"] { font-family: 'Noto Sans KR', sans-serif; background-color: #f4f6f9; }
    .card {
        background: white; padding: 22px; border-radius: 20px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.06); margin-bottom: 24px;
        border: 1px solid #eef1f4; height: 100%; display: flex; flex-direction: column;
    }
    .card-title { font-size: 1.1rem; font-weight: 700; color: #1a1c1e; margin-bottom: 12px; line-height: 1.4; height: 50px; overflow: hidden; display: -webkit-box; -webkit-line-clamp: 2; -webkit-box-orient: vertical; }
    .card-summary { font-size: 0.9rem; color: #515458; line-height: 1.6; margin-bottom: 15px; flex-grow: 1; overflow: hidden; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; }
    .thumbnail { width: 100%; height: 190px; object-fit: cover; border-radius: 14px; margin-bottom: 16px; background-color: #eee; }
    .badge { background: #f0f4ff; color: #1a73e8; padding: 4px 10px; border-radius: 6px; font-size: 0.75rem; font-weight: 700; margin-bottom: 10px; display: inline-block; }
</style>
""", unsafe_allow_html=True)

# --- 4. ë°ì´í„° ì²˜ë¦¬ ì—”ì§„ ---
def get_ai_model():
    if not st.session_state.settings["api_key"]: return None
    genai.configure(api_key=st.session_state.settings["api_key"])
    for name in ['gemini-1.5-flash', 'gemini-1.5-flash-latest']:
        try:
            model = genai.GenerativeModel(name)
            model.generate_content("test", generation_config={"max_output_tokens": 1})
            return model
        except: continue
    return None

@st.cache_data(ttl=3600)
def fetch_sensing_data():
    all_data = []
    limit = datetime.now() - timedelta(days=st.session_state.settings["sensing_period"])
    translator = GoogleTranslator(source='auto', target='ko')

    for cat, feeds in st.session_state.settings["channels"].items():
        for f in feeds:
            if not f["active"]: continue
            d = feedparser.parse(f["url"])
            for entry in d.entries[:10]:
                try:
                    p_date = datetime.fromtimestamp(time.mktime(entry.published_parsed))
                    if p_date < limit: continue
                    
                    # ì œëª©/ìš”ì•½ í•œê¸€ ë²ˆì—­
                    title_ko = translator.translate(entry.title)
                    summary_raw = BeautifulSoup(entry.get("summary", ""), "html.parser").get_text()[:250]
                    summary_ko = translator.translate(summary_raw)

                    all_data.append({
                        "title": title_ko,
                        "summary": summary_ko,
                        "img": get_robust_thumbnail(entry), # ê°œì„ ëœ ë¡œì§ ì ìš©
                        "source": f["name"],
                        "date": p_date.strftime("%m/%d"),
                        "link": entry.link
                    })
                except: continue
    all_data.sort(key=lambda x: x['date'], reverse=True)
    return all_data

# --- 5. ì‚¬ì´ë“œë°” ë° ë©”ì¸ í™”ë©´ ---
with st.sidebar:
    st.title("ğŸ›¡ï¸ NOD ì „ëµ ì„¼í„°")
    if st.session_state.settings["api_key"]:
        st.success("âœ… AI ê°€ë™ ì¤‘")
        if st.button("Key ë³€ê²½"): st.session_state.settings["api_key"] = ""; st.rerun()
    else:
        new_key = st.text_input("Gemini API Key", type="password")
        if st.button("ì—°ê²°"): 
            st.session_state.settings["api_key"] = new_key
            save_settings(st.session_state.settings); st.rerun()

    st.divider()
    st.subheader("ğŸŒ ì±„ë„ ê´€ë¦¬")
    for cat, feeds in st.session_state.settings["channels"].items():
        with st.expander(cat):
            for f in feeds:
                f["active"] = st.checkbox(f["name"], value=f["active"], key=f"ch_{f['name']}")

    st.divider()
    with st.expander("âš™ï¸ ê³ ê¸‰ ì„¤ì •"):
        st.session_state.settings["filter_prompt"] = st.text_area("í•„í„° ê¸°ì¤€", value=st.session_state.settings["filter_prompt"])
        st.session_state.settings["ai_analysis_prompt"] = st.text_area("ë¶„ì„ í”„ë¡¬í”„íŠ¸", value=st.session_state.settings["ai_analysis_prompt"])
        if st.button("ì„¤ì • ì €ì¥"):
            save_settings(st.session_state.settings)
            st.toast("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

st.title("ğŸš€ NOD Intelligence Dashboard")
news_data = fetch_sensing_data()

model = get_ai_model()
if news_data:
    # 3ì—´ ë°°ì¹˜
    rows = [news_data[i:i + 3] for i in range(0, len(news_data), 3)]
    for row in rows:
        cols = st.columns(3)
        for i, item in enumerate(row):
            with cols[i]:
                st.markdown(f"""
                <div class="card">
                    <div class="badge">{item['source']} | {item['date']}</div>
                    <img src="{item['img']}" class="thumbnail">
                    <div class="card-title">{item['title']}</div>
                    <div class="card-summary">{item['summary']}...</div>
                    <p style="font-size:0.8rem;"><a href="{item['link']}" target="_blank">ì›ë³¸ ê¸°ì‚¬ ë³´ê¸°</a></p>
                </div>
                """, unsafe_allow_html=True)
                if st.button("ğŸ” ì „ëµ Deep-dive", key=f"btn_{item['link'][-10:]}"):
                    if model:
                        with st.spinner("AI ë¶„ì„ ì¤‘..."):
                            res = model.generate_content(f"{st.session_state.settings['ai_analysis_prompt']}\n\në‚´ìš©: {item['title']} - {item['summary']}")
                            st.info(res.text)
                    else: st.warning("API Keyë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
else:
    st.info("ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘ ì¤‘ì´ê±°ë‚˜ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
